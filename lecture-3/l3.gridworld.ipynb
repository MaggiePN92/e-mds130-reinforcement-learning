{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "import random\n",
    "\n",
    "# Set the seed values\n",
    "torch.seed = 1234\n",
    "np.random.seed(torch.seed)\n",
    "random.seed(torch.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridWorld Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld():\n",
    "    def __init__(self, d=4, mode='static'):\n",
    "        if d < 4:\n",
    "            raise Exception(\"Minimum dimension should be equal to 4!\")\n",
    "        \n",
    "        if mode not in ['static', 'player', 'random']:\n",
    "            raise Exception(\"The mode should be either static, player or random.\")\n",
    "        self.mode = mode\n",
    "        self.d = d\n",
    "        # We set the max number of moves that can be played in a game\n",
    "        self.maxMoves = self.d**3\n",
    "        # Max reward positive or negative for win or loss\n",
    "        self.artifacts = ['_', '|', '+', '-', 'P'] \n",
    "        self.artifactsMap = {'_': 0, '|': 1, '+': 2, '-': 3, 'P': 4}       \n",
    "        self.rewardMap = {'_': -1, '+': 100, '-': -100}\n",
    "        self.actionSpace = {'up': (-1, 0), 'right': (0, 1), 'down': (1, 0), 'left': (0, -1)}               \n",
    "        \n",
    "        # Initialize the environment\n",
    "        _ = self.reset()\n",
    "\n",
    "\n",
    "        # Set the params for rendering\n",
    "        self.renderprops = {}\n",
    "        self.renderprops['left'], self.renderprops['width'] = .25, .5\n",
    "        self.renderprops['bottom'], self.renderprops['height'] = .25, .5\n",
    "        self.renderprops['right'] = self.renderprops['left'] + self.renderprops['width']\n",
    "        self.renderprops['top'] = self.renderprops['bottom'] + self.renderprops['height']\n",
    "\n",
    "        self.renderprops['fig'], self.renderprops['ax'] = plt.subplots(figsize=(1,1))       \n",
    "        # We dont want to show the figure at this point \n",
    "        plt.close()\n",
    "\n",
    "    # Transform the grid to a multi-dimensional array\n",
    "    def transformGrid(self):\n",
    "        grid = []\n",
    "        artifacts = ['|', '+', '-', 'P']\n",
    "        for a in artifacts:\n",
    "            plane = np.zeros_like(self.grid, dtype=np.int8)\n",
    "            for b in artifacts:\n",
    "                if a == b:\n",
    "                    plane = np.where(self.grid == b, 1, plane)\n",
    "            grid.append(plane)\n",
    "        return np.array(grid)\n",
    "\n",
    "    # Reset to initial state\n",
    "    def reset(self):\n",
    "        # Set the current move\n",
    "        self.moveCount = 0\n",
    "         # Create a empty grid with all places as open\n",
    "        self.grid = np.tile(np.array(self.artifacts[0]), (self.d, self.d))\n",
    "\n",
    "        # If the mode is static, set all positions as constant\n",
    "        if self.mode == 'static':\n",
    "            # Update the grid with wall, win, loss and player positons\n",
    "            self.grid[2, 2] = self.artifacts[1] # Wall\n",
    "            self.grid[0, 0] = self.artifacts[2] # Win\n",
    "            self.grid[0, 3] = self.artifacts[3] # Loss\n",
    "            self.grid[3, 2] = self.artifacts[4] # Player\n",
    "\n",
    "            # record the player, win and loss locations\n",
    "            self.wallPos = np.array([2, 2])\n",
    "            self.winPos = np.array([0, 0])\n",
    "            self.lossPos = np.array([0, 3])\n",
    "            self.playerPos = np.array([3, 2])\n",
    "        # If mode is player, set the player position to random\n",
    "        elif self.mode == 'player':\n",
    "            # Update the grid with wall, win and loss locations\n",
    "            self.grid[2, 2] = self.artifacts[1] # Wall\n",
    "            self.grid[0, 0] = self.artifacts[2] # Win\n",
    "            self.grid[0, 3] = self.artifacts[3] # Loss\n",
    "\n",
    "            # record the win and loss locations    \n",
    "            self.wallPos = np.array([2, 2])        \n",
    "            self.winPos = np.array([0, 0])\n",
    "            self.lossPos = np.array([0, 3])\n",
    "\n",
    "            # Set the playerPos to random            \n",
    "            self.playerPos = np.random.choice(self.d, size=2)            \n",
    "            # Ensure that the player position is not the same as the win, loss and wall positions\n",
    "            while (self.playerPos == self.winPos).all() or (self.playerPos == self.lossPos).all() or (self.playerPos == self.wallPos).all():\n",
    "                self.playerPos = np.random.choice(self.d, size=2)\n",
    "            \n",
    "            # Update the grid with the player position\n",
    "            self.grid[self.playerPos[0], self.playerPos[1]] = self.artifacts[4] # Player            \n",
    "        else:\n",
    "            # Set the playerPos to random            \n",
    "            self.playerPos = np.random.choice(self.d, size=2)  \n",
    "            \n",
    "            # Set the winPos to random\n",
    "            self.winPos = np.random.choice(self.d, size=2)  \n",
    "            # Ensure that the win position is not the same as the player position\n",
    "            while (self.winPos == self.playerPos).all():\n",
    "                self.winPos = np.random.choice(self.d, size=2)\n",
    "\n",
    "            # Set the lossPos to random\n",
    "            self.lossPos = np.random.choice(self.d, size=2)  \n",
    "            # Ensure that the loss position is not the same as the player or win position\n",
    "            while (self.lossPos == self.playerPos).all() or (self.lossPos == self.winPos).all():\n",
    "                self.lossPos = np.random.choice(self.d, size=2)\n",
    "            \n",
    "            # Set the wallPoss to random\n",
    "            self.wallPos = np.random.choice(self.d, size=2)  \n",
    "            # Ensure that the wall position is not the same as the player or win or loss position\n",
    "            while (self.wallPos == self.playerPos).all() or (self.wallPos == self.winPos).all() or (self.wallPos == self.lossPos).all():\n",
    "                self.wallPos = np.random.choice(self.d, size=2)\n",
    "            \n",
    "            # Update the grid with the positions\n",
    "            self.grid[self.wallPos[0], self.wallPos[1]] = self.artifacts[1] # Wall\n",
    "            self.grid[self.winPos[0], self.winPos[1]] = self.artifacts[2] # Win\n",
    "            self.grid[self.lossPos[0], self.lossPos[1]] = self.artifacts[3] # Loss\n",
    "            self.grid[self.playerPos[0], self.playerPos[1]] = self.artifacts[4] # Player\n",
    "\n",
    "        return self.transformGrid().flatten()\n",
    "\n",
    "    # Perform an action, modify the state, get the new state, reward and status information\n",
    "    def step(self, action):\n",
    "        if action not in self.actionSpace.keys():\n",
    "            raise Exception('Action not present in action space')\n",
    "\n",
    "        # Increment the moveCount\n",
    "        self.moveCount += 1\n",
    "        info = ''\n",
    "        # Check if its already game over.\n",
    "        done = True if (self.playerPos == self.winPos).all() or (self.playerPos == self.lossPos).all() else False\n",
    "        reward = -1\n",
    "\n",
    "        x, y = copy.copy(self.playerPos) + self.actionSpace[action]\n",
    "        if self.moveCount < self.maxMoves:\n",
    "            if  not done:                                    \n",
    "                # Check that we are not at the edges\n",
    "                if x >= 0 and x < self.d and y >= 0 and y < self.d:\n",
    "                    # We allow the player to transition to the new position if the new postion doesnot contain a wall\n",
    "                    if self.grid[x, y] != '|':\n",
    "                        # record the reward the player will receive after transitioning to this new position\n",
    "                        reward = self.rewardMap[self.grid[x, y]]\n",
    "                        # Check if its game won or over\n",
    "                        if self.grid[x, y] == '+' or self.grid[x, y] == '-':\n",
    "                            done = True\n",
    "                        # Update the grid with this new transition                             \n",
    "                        self.grid[x, y] = 'P'\n",
    "                        self.grid[self.playerPos[0], self.playerPos[1]] = '_'\n",
    "                        \n",
    "                        # Update the player position\n",
    "                        self.playerPos = np.array([x, y])\n",
    "        else:\n",
    "            done = True\n",
    "\n",
    "        # Return the next state, reward received, is done flag and any other info                \n",
    "        return self.transformGrid().flatten(), reward, done, info\n",
    "\n",
    "    # Renders the game to the screen\n",
    "    def render(self):\n",
    "        self.renderprops['ax'].cla()\n",
    "        self.renderprops['ax'].axis('off')\n",
    "        self.renderprops['ax'].text(0.5*(self.renderprops['left']+self.renderprops['right']), 0.5*(self.renderprops['bottom']+self.renderprops['top']), re.sub(\"[\\'\\[\\]]\", '', np.array2string(self.grid)),\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center',\n",
    "            fontsize=20, color='red')        \n",
    "        display(self.renderprops['fig'])\n",
    "\n",
    "        clear_output(wait = True)\n",
    "        plt.pause(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridWorld Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "class Agent():\n",
    "    def __init__(self, envDimension=4, learningRate=1e-3, gamma=0.9, maxEpsilon = 1, minEpsilon=0.1, device='cpu'):\n",
    "        # Store the params\n",
    "        self.device = device\n",
    "        self.envDimension = envDimension\n",
    "        self.learningRate = learningRate\n",
    "        self.gamma = gamma\n",
    "        self.maxEpsilon = maxEpsilon\n",
    "        self.minEpsilon = minEpsilon\n",
    "        # Get the available list of actions that can be performed in the game\n",
    "        self.availableActions = list(GridWorld(self.envDimension, mode='static').actionSpace.keys())\n",
    "                        \n",
    "    \n",
    "    def createModel(self):        \n",
    "        model = torch.nn.Sequential(\n",
    "        # Input -> Hidden1\n",
    "        torch.nn.Linear(64, 150),\n",
    "        torch.nn.ReLU(),\n",
    "        # Hidden1 -> Hidden2\n",
    "        torch.nn.Linear(150, 100),\n",
    "        torch.nn.ReLU(),\n",
    "        # Hidden2 -> Output\n",
    "        torch.nn.Linear(100, 4))\n",
    "\n",
    "        # Add the model\n",
    "        self.model = model.to(self.device)\n",
    "        # We also create copy of the model as a target model. We use it if OET algo is used\n",
    "        self.targetmodel = copy.deepcopy(self.model)\n",
    "        self.targetmodel.load_state_dict(self.model.state_dict())\n",
    "        \n",
    "        return self.model, optim.Adam(model.parameters(), lr = self.learningRate), nn.MSELoss()\n",
    "\n",
    "    def backward(self, loss, optimizer):\n",
    "        # Backprop                    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    def train(self, algo, mode='static', epochs=1000, memSize=1000, batchSize=200, syncFreq=500):                 \n",
    "        if algo.upper() not in ['Q', 'QE', 'QET']:            \n",
    "            raise Exception('The algorithm used for training should be Q: for Q Learning, QE: for Experiance Replay and QET: for Experiance Replay with a Target Network')\n",
    "        # Create the model to train\n",
    "        model, optimizer, lossfun = self.createModel()\n",
    "        # Set the epsilon value\n",
    "        epsilon = self.maxEpsilon\n",
    "        # Store the losses. We will plot it later\n",
    "        losses = []\n",
    "        # Named tuple to store the experiences if we are using experiance replay\n",
    "        Experience = namedtuple('buffer', field_names=['state', 'action', 'reward', 'done', 'nextState'])\n",
    "        # We also need a replay buffer for experiance replay\n",
    "        replay = deque(maxlen=memSize)\n",
    "\n",
    "        # The sync of params to the target network is controlled via a variable. Will be used only if QET algo is applied\n",
    "        targetNetworkSyncController = 0\n",
    "        for e in range(epochs):            \n",
    "            # Instantiate the environment for the current epoch\n",
    "            env = GridWorld(self.envDimension, mode=mode)\n",
    "            # Reset the environment and convert it to a tensor.\n",
    "            state = torch.from_numpy(env.reset()).to(self.device).float()\n",
    "\n",
    "            # Set the game status to not done\n",
    "            done = False            \n",
    "            # Play until the game doesnot end\n",
    "            while not done:\n",
    "                targetNetworkSyncController += 1\n",
    "                Q = model(state)\n",
    "                Q_ = Q.data.cpu().numpy()\n",
    "                action_ = \"\"\n",
    "                if(np.random.random() < epsilon):\n",
    "                    # Choose one of the valid options            \n",
    "                    action_ = np.random.choice(len(self.availableActions))\n",
    "                else:                                     \n",
    "                    action_ = np.argmax(Q_)\n",
    "\n",
    "                # Step through the environment\n",
    "                nextState_, reward, done, _ = env.step(self.availableActions[action_])\n",
    "                # Evaluate the Q Vals for the next state\n",
    "                nextState = torch.from_numpy(nextState_).to(self.device).float()\n",
    "                \n",
    "                # Add to memory, will be used only if we are using QE or QET algo\n",
    "                replay.append(Experience(state, action_, reward, done, nextState))\n",
    "\n",
    "                state = nextState\n",
    "                if algo in ['QE', 'QET']:\n",
    "                    if len(replay) > batchSize:\n",
    "                        miniBatchIndices = np.random.choice(len(replay), batchSize, replace=False)                                                                                              \n",
    "                        stateBatch = torch.stack([ replay[idx].state  for idx in miniBatchIndices]).to(self.device)\n",
    "                        actionBatch = torch.Tensor([ replay[idx].action  for idx in miniBatchIndices]).to(self.device)        \n",
    "                        rewardBatch = torch.Tensor([ replay[idx].reward  for idx in miniBatchIndices]).to(self.device)                        \n",
    "                        doneBatch = torch.Tensor([ replay[idx].done  for idx in miniBatchIndices]).to(self.device)\n",
    "                        nextStateBatch = torch.stack([ replay[idx].nextState  for idx in miniBatchIndices]).to(self.device)                   \n",
    "                        \n",
    "                        QExp = model(stateBatch)  \n",
    "                        \n",
    "                        nextQExp = None\n",
    "                        if algo == 'QE': # If only experiance replay is used\n",
    "                            with torch.no_grad():\n",
    "                                nextQExp = model(nextStateBatch)\n",
    "                        else: # If experiance replay with a target network is used (QET)\n",
    "                            with torch.no_grad():\n",
    "                                # We use the target network to get the maximum Q value for the next state\n",
    "                                nextQExp = self.targetmodel(nextStateBatch) \n",
    "                        \n",
    "                        # Expected State Action Value                        \n",
    "                        YHat = rewardBatch + self.gamma * ((1 - doneBatch) * torch.max(nextQExp, dim=1)[0])                        \n",
    "                        \n",
    "                        # Current State Action Value\n",
    "                        Y = QExp.gather(dim=1, index=actionBatch.long().unsqueeze(dim=1)).squeeze()\n",
    "                        \n",
    "                        # Backprop\n",
    "                        loss = lossfun(Y, YHat)\n",
    "                        losses.append(loss.item())\n",
    "                        self.backward(loss, optimizer)       \n",
    "\n",
    "                        # Copies the main model parameters to the target network\n",
    "                        if targetNetworkSyncController % syncFreq == 0:\n",
    "                            self.targetmodel.load_state_dict(self.model.state_dict())                                 \n",
    "                else: # IF we are using Q algo\n",
    "                    with torch.no_grad():\n",
    "                        nextQ = model(nextState)                        \n",
    "\n",
    "                    # Max state action value we will receive if the choosen action is taken in the current step\n",
    "                    maxNextQ = torch.max(nextQ)                    \n",
    "\n",
    "                    # Estimated future rewards\n",
    "                    if not done:\n",
    "                        YHat = reward + (self.gamma * maxNextQ)\n",
    "                    else:\n",
    "                        YHat = reward\n",
    "                    \n",
    "                    YHat = torch.Tensor([YHat]).detach().to(self.device)                                       \n",
    "\n",
    "                    # Current state action value\n",
    "                    Y = Q.squeeze()[action_]            \n",
    "                                \n",
    "                    # Backprop\n",
    "                    loss = lossfun(Y, YHat)\n",
    "                    losses.append(loss.item())\n",
    "                    self.backward(loss, optimizer,)                                    \n",
    "                             \n",
    "            # Adapt the epsilon value\n",
    "            if epsilon > self.minEpsilon:\n",
    "                epsilon -= (1/1000)        \n",
    "\n",
    "            # Print the progress\n",
    "            if e % np.round(epochs/10) == 0:       \n",
    "                error = np.mean(losses)\n",
    "                print('epoch: {:d}, error: {:.2f}'.format(e, error))\n",
    "        plt.plot(losses)\n",
    "\n",
    "    # A function to test the trained model\n",
    "    def test(self, numGames=10, mode='static', display=False):\n",
    "        # Number of games to test on    \n",
    "        numWins = 0\n",
    "        numLoss = 0\n",
    "\n",
    "        for g in range(numGames):        \n",
    "            # Testing\n",
    "            testEnv = GridWorld(4, mode=mode)        \n",
    "            state = torch.from_numpy(testEnv.reset()).to(self.device).float()\n",
    "                        \n",
    "            m = 0        \n",
    "            done = False\n",
    "            maxMoves = 10\n",
    "            while not done and maxMoves > 0:\n",
    "                maxMoves -= 1\n",
    "                Q = self.model(state)\n",
    "                Q_ = Q.data.cpu().numpy()                        \n",
    "                # Set the invalid actions qval to neg. inf.                               \n",
    "                action_ = np.argmax(Q_)    \n",
    "                action = self.availableActions[action_]\n",
    "                \n",
    "                nextState_, reward, done, _ = testEnv.step(action)    \n",
    "                state = torch.from_numpy(nextState_).to(self.device).float()\n",
    "                \n",
    "                m += 1         \n",
    "                \n",
    "                if display: # Render the moves to screen\n",
    "                    testEnv.render() # Render it\n",
    "                else:# If rendering is off, we print some status\n",
    "                    print('GAME: {}. Move #: {}; Took action: {}; Reward received: {}'.format(g+1, m, action, reward))                    \n",
    "                \n",
    "                if done:                \n",
    "                    # If the end reward is 100, we have a win\n",
    "                    if reward == 100:\n",
    "                        numWins += 1\n",
    "                    if reward == -100:\n",
    "                        numLoss += 1\n",
    "            \n",
    "        print('Total games played={}. Of which {} are won, {} are lost, and {} were abandoned'.format(numGames, numWins, numLoss, numGames - numWins - numLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA present: True\n",
      "If you would like to use the GPU, pass the param device=\"cuda\" to your Agent constructor\n"
     ]
    }
   ],
   "source": [
    "# Check if you have a GPU and that cuda is configured\n",
    "isGPU = torch.cuda.is_available()\n",
    "print('Is CUDA present:', isGPU)\n",
    "if isGPU:\n",
    "    print('If you would like to use the GPU, pass the param device=\"cuda\" to your Agent constructor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chakr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:529: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, error: 419.55\n",
      "epoch: 100, error: 260.26\n",
      "epoch: 200, error: 196.91\n",
      "epoch: 300, error: 173.24\n",
      "epoch: 400, error: 158.29\n",
      "epoch: 500, error: 144.86\n",
      "epoch: 600, error: 134.25\n",
      "epoch: 700, error: 124.21\n",
      "epoch: 800, error: 117.14\n",
      "epoch: 900, error: 111.67\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the agent\n",
    "agent = Agent()\n",
    "# Train the agent\n",
    "agent.train(algo='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games played=1. Of which 1 are won, 0 are lost, and 0 were abandoned\n"
     ]
    }
   ],
   "source": [
    "# Test on static mode\n",
    "agent.test(numGames=1, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games played=10. Of which 10 are won, 0 are lost, and 0 were abandoned\n"
     ]
    }
   ],
   "source": [
    "# Test on player mode\n",
    "agent.test(numGames=10, mode='player', display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games played=10. Of which 1 are won, 0 are lost, and 9 were abandoned\n"
     ]
    }
   ],
   "source": [
    "# Test on random mode\n",
    "agent.test(numGames=10, mode='random', display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning with Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chakr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\chakr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, error: nan\n",
      "epoch: 500, error: 85.95\n",
      "epoch: 1000, error: 47.35\n",
      "epoch: 1500, error: 36.46\n",
      "epoch: 2000, error: 32.15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\ubuntu-data\\dev\\E-MDS130-1-22V\\code\\l3.gridworld.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000012?line=1'>2</a>\u001b[0m agent \u001b[39m=\u001b[39m Agent(minEpsilon\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000012?line=2'>3</a>\u001b[0m \u001b[39m# Train the agent\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000012?line=3'>4</a>\u001b[0m agent\u001b[39m.\u001b[39;49mtrain(algo\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mQE\u001b[39;49m\u001b[39m'\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m'\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m5000\u001b[39;49m, memSize\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batchSize\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n",
      "\u001b[1;32me:\\ubuntu-data\\dev\\E-MDS130-1-22V\\code\\l3.gridworld.ipynb Cell 5'\u001b[0m in \u001b[0;36mAgent.train\u001b[1;34m(self, algo, mode, epochs, memSize, batchSize, syncFreq)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000004?line=55'>56</a>\u001b[0m targetNetworkSyncController \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000004?line=56'>57</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):            \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000004?line=57'>58</a>\u001b[0m     \u001b[39m# Instantiate the environment for the current epoch\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000004?line=58'>59</a>\u001b[0m     env \u001b[39m=\u001b[39m GridWorld(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvDimension, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000004?line=59'>60</a>\u001b[0m     \u001b[39m# Reset the environment and convert it to a tensor.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000004?line=60'>61</a>\u001b[0m     state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(env\u001b[39m.\u001b[39mreset())\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mfloat()\n",
      "\u001b[1;32me:\\ubuntu-data\\dev\\E-MDS130-1-22V\\code\\l3.gridworld.ipynb Cell 3'\u001b[0m in \u001b[0;36mGridWorld.__init__\u001b[1;34m(self, d, mode)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000002?line=25'>26</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrenderprops[\u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrenderprops[\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrenderprops[\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000002?line=26'>27</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrenderprops[\u001b[39m'\u001b[39m\u001b[39mtop\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrenderprops[\u001b[39m'\u001b[39m\u001b[39mbottom\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrenderprops[\u001b[39m'\u001b[39m\u001b[39mheight\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000002?line=28'>29</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrenderprops[\u001b[39m'\u001b[39m\u001b[39mfig\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrenderprops[\u001b[39m'\u001b[39m\u001b[39max\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49msubplots(figsize\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m))       \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000002?line=29'>30</a>\u001b[0m \u001b[39m# We dont want to show the figure at this point \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ubuntu-data/dev/E-MDS130-1-22V/code/l3.gridworld.ipynb#ch0000002?line=30'>31</a>\u001b[0m plt\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\pyplot.py:1435\u001b[0m, in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1301'>1302</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1302'>1303</a>\u001b[0m \u001b[39mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1303'>1304</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1431'>1432</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1432'>1433</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1433'>1434</a>\u001b[0m fig \u001b[39m=\u001b[39m figure(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfig_kw)\n\u001b[1;32m-> <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1434'>1435</a>\u001b[0m axs \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49msubplots(nrows\u001b[39m=\u001b[39;49mnrows, ncols\u001b[39m=\u001b[39;49mncols, sharex\u001b[39m=\u001b[39;49msharex, sharey\u001b[39m=\u001b[39;49msharey,\n\u001b[0;32m   <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1435'>1436</a>\u001b[0m                    squeeze\u001b[39m=\u001b[39;49msqueeze, subplot_kw\u001b[39m=\u001b[39;49msubplot_kw,\n\u001b[0;32m   <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1436'>1437</a>\u001b[0m                    gridspec_kw\u001b[39m=\u001b[39;49mgridspec_kw)\n\u001b[0;32m   <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/pyplot.py?line=1437'>1438</a>\u001b[0m \u001b[39mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\figure.py:897\u001b[0m, in \u001b[0;36mFigureBase.subplots\u001b[1;34m(self, nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=894'>895</a>\u001b[0m     gridspec_kw \u001b[39m=\u001b[39m {}\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=895'>896</a>\u001b[0m gs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_gridspec(nrows, ncols, figure\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgridspec_kw)\n\u001b[1;32m--> <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=896'>897</a>\u001b[0m axs \u001b[39m=\u001b[39m gs\u001b[39m.\u001b[39;49msubplots(sharex\u001b[39m=\u001b[39;49msharex, sharey\u001b[39m=\u001b[39;49msharey, squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=897'>898</a>\u001b[0m                   subplot_kw\u001b[39m=\u001b[39;49msubplot_kw)\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=898'>899</a>\u001b[0m \u001b[39mreturn\u001b[39;00m axs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\gridspec.py:307\u001b[0m, in \u001b[0;36mGridSpecBase.subplots\u001b[1;34m(self, sharex, sharey, squeeze, subplot_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/gridspec.py?line=304'>305</a>\u001b[0m         subplot_kw[\u001b[39m\"\u001b[39m\u001b[39msharex\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m shared_with[sharex]\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/gridspec.py?line=305'>306</a>\u001b[0m         subplot_kw[\u001b[39m\"\u001b[39m\u001b[39msharey\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m shared_with[sharey]\n\u001b[1;32m--> <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/gridspec.py?line=306'>307</a>\u001b[0m         axarr[row, col] \u001b[39m=\u001b[39m figure\u001b[39m.\u001b[39madd_subplot(\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/gridspec.py?line=307'>308</a>\u001b[0m             \u001b[39mself\u001b[39m[row, col], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msubplot_kw)\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/gridspec.py?line=309'>310</a>\u001b[0m \u001b[39m# turn off redundant tick labeling\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/gridspec.py?line=310'>311</a>\u001b[0m \u001b[39mif\u001b[39;00m sharex \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\figure.py:772\u001b[0m, in \u001b[0;36mFigureBase.add_subplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=768'>769</a>\u001b[0m         args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m(args[\u001b[39m0\u001b[39m])))\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=769'>770</a>\u001b[0m     projection_class, pkw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_projection_requirements(\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=770'>771</a>\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=771'>772</a>\u001b[0m     ax \u001b[39m=\u001b[39m subplot_class_factory(projection_class)(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpkw)\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=772'>773</a>\u001b[0m     key \u001b[39m=\u001b[39m (projection_class, pkw)\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/figure.py?line=773'>774</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_axes_internal(ax, key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\axes\\_subplots.py:34\u001b[0m, in \u001b[0;36mSubplotBase.__init__\u001b[1;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_subplots.py?line=14'>15</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_subplots.py?line=15'>16</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_subplots.py?line=16'>17</a>\u001b[0m \u001b[39m----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_subplots.py?line=30'>31</a>\u001b[0m \u001b[39m    Keyword arguments are passed to the Axes (sub)class constructor.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_subplots.py?line=31'>32</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_subplots.py?line=32'>33</a>\u001b[0m \u001b[39m# _axes_class is set in the subplot_class_factory\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_subplots.py?line=33'>34</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_axes_class\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, fig, [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_subplots.py?line=34'>35</a>\u001b[0m \u001b[39m# This will also update the axes position.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_subplots.py?line=35'>36</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_subplotspec(SubplotSpec\u001b[39m.\u001b[39m_from_subplot_args(fig, args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\_api\\deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/_api/deprecation.py?line=449'>450</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/_api/deprecation.py?line=450'>451</a>\u001b[0m     warn_deprecated(\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/_api/deprecation.py?line=451'>452</a>\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/_api/deprecation.py?line=452'>453</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/_api/deprecation.py?line=453'>454</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/_api/deprecation.py?line=454'>455</a>\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/_api/deprecation.py?line=455'>456</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\axes\\_base.py:606\u001b[0m, in \u001b[0;36m_AxesBase.__init__\u001b[1;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_base.py?line=603'>604</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_position\u001b[39m.\u001b[39mwidth \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_position\u001b[39m.\u001b[39mheight \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_base.py?line=604'>605</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mWidth and height specified must be non-negative\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_base.py?line=605'>606</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_originalPosition \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_position\u001b[39m.\u001b[39;49mfrozen()\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_base.py?line=606'>607</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/axes/_base.py?line=607'>608</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aspect \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\transforms.py:800\u001b[0m, in \u001b[0;36mBbox.frozen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/transforms.py?line=796'>797</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrozen\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/transforms.py?line=797'>798</a>\u001b[0m     \u001b[39m# docstring inherited\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/transforms.py?line=798'>799</a>\u001b[0m     frozen_bbox \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfrozen()\n\u001b[1;32m--> <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/transforms.py?line=799'>800</a>\u001b[0m     frozen_bbox\u001b[39m.\u001b[39m_minpos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mminpos\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m    <a href='file:///c%3A/Users/chakr/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/matplotlib/transforms.py?line=800'>801</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m frozen_bbox\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 72x72 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the agent\n",
    "agent = Agent(minEpsilon=0.01, device='cuda')\n",
    "# Train the agent\n",
    "agent.train(algo='QE', mode='random', epochs=5000, memSize=1000, batchSize=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games played=1. Of which 1 are won, 0 are lost, and 0 were abandoned\n"
     ]
    }
   ],
   "source": [
    "# Test on static mode\n",
    "agent.test(numGames=1, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME: 1. Move #: 1; Took action: left; Reward received: -1\n",
      "GAME: 1. Move #: 2; Took action: left; Reward received: -1\n",
      "GAME: 1. Move #: 3; Took action: up; Reward received: -1\n",
      "GAME: 1. Move #: 4; Took action: up; Reward received: -1\n",
      "GAME: 1. Move #: 5; Took action: up; Reward received: -1\n",
      "GAME: 1. Move #: 6; Took action: left; Reward received: 100\n",
      "GAME: 2. Move #: 1; Took action: up; Reward received: -1\n",
      "GAME: 2. Move #: 2; Took action: up; Reward received: -1\n",
      "GAME: 2. Move #: 3; Took action: left; Reward received: 100\n",
      "GAME: 3. Move #: 1; Took action: left; Reward received: 100\n",
      "GAME: 4. Move #: 1; Took action: up; Reward received: -1\n",
      "GAME: 4. Move #: 2; Took action: left; Reward received: 100\n",
      "GAME: 5. Move #: 1; Took action: up; Reward received: -1\n",
      "GAME: 5. Move #: 2; Took action: left; Reward received: 100\n",
      "GAME: 6. Move #: 1; Took action: left; Reward received: 100\n",
      "GAME: 7. Move #: 1; Took action: left; Reward received: -1\n",
      "GAME: 7. Move #: 2; Took action: left; Reward received: -1\n",
      "GAME: 7. Move #: 3; Took action: up; Reward received: -1\n",
      "GAME: 7. Move #: 4; Took action: up; Reward received: -1\n",
      "GAME: 7. Move #: 5; Took action: up; Reward received: -1\n",
      "GAME: 7. Move #: 6; Took action: left; Reward received: 100\n",
      "GAME: 8. Move #: 1; Took action: left; Reward received: -1\n",
      "GAME: 8. Move #: 2; Took action: up; Reward received: -1\n",
      "GAME: 8. Move #: 3; Took action: up; Reward received: -1\n",
      "GAME: 8. Move #: 4; Took action: up; Reward received: -1\n",
      "GAME: 8. Move #: 5; Took action: left; Reward received: 100\n",
      "GAME: 9. Move #: 1; Took action: left; Reward received: -1\n",
      "GAME: 9. Move #: 2; Took action: up; Reward received: -1\n",
      "GAME: 9. Move #: 3; Took action: left; Reward received: -1\n",
      "GAME: 9. Move #: 4; Took action: left; Reward received: 100\n",
      "GAME: 10. Move #: 1; Took action: up; Reward received: 100\n",
      "Total games played=10. Of which 10 are won, 0 are lost, and 0 were abandoned\n"
     ]
    }
   ],
   "source": [
    "# Test on player mode\n",
    "agent.test(numGames=10, mode='player', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games played=10. Of which 9 are won, 0 are lost, and 1 were abandoned\n"
     ]
    }
   ],
   "source": [
    "# Test on random mode\n",
    "agent.test(numGames=10, mode='random', display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning with Experience Replay and a Target Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, error: nan\n",
      "epoch: 500, error: 69.24\n",
      "epoch: 1000, error: 65.41\n",
      "epoch: 1500, error: 52.67\n",
      "epoch: 2000, error: 49.15\n",
      "epoch: 2500, error: 46.66\n",
      "epoch: 3000, error: 45.23\n",
      "epoch: 3500, error: 44.02\n",
      "epoch: 4000, error: 43.14\n",
      "epoch: 4500, error: 42.62\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the agent\n",
    "agent = Agent(minEpsilon=0.01, device='cuda')\n",
    "# Train the agent\n",
    "agent.train(algo='QET', mode='random', epochs=5000, memSize=1000, batchSize=200, syncFreq=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games played=1. Of which 1 are won, 0 are lost, and 0 were abandoned\n"
     ]
    }
   ],
   "source": [
    "# Test on static mode\n",
    "agent.test(numGames=1, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME: 1. Move #: 1; Took action: up; Reward received: -1\n",
      "GAME: 1. Move #: 2; Took action: up; Reward received: -1\n",
      "GAME: 1. Move #: 3; Took action: up; Reward received: 100\n",
      "GAME: 2. Move #: 1; Took action: left; Reward received: 100\n",
      "GAME: 3. Move #: 1; Took action: up; Reward received: -1\n",
      "GAME: 3. Move #: 2; Took action: left; Reward received: -1\n",
      "GAME: 3. Move #: 3; Took action: left; Reward received: -1\n",
      "GAME: 3. Move #: 4; Took action: left; Reward received: -1\n",
      "GAME: 3. Move #: 5; Took action: up; Reward received: 100\n",
      "GAME: 4. Move #: 1; Took action: left; Reward received: 100\n",
      "GAME: 5. Move #: 1; Took action: left; Reward received: -1\n",
      "GAME: 5. Move #: 2; Took action: left; Reward received: -1\n",
      "GAME: 5. Move #: 3; Took action: left; Reward received: -1\n",
      "GAME: 5. Move #: 4; Took action: up; Reward received: -1\n",
      "GAME: 5. Move #: 5; Took action: up; Reward received: -1\n",
      "GAME: 5. Move #: 6; Took action: up; Reward received: 100\n",
      "GAME: 6. Move #: 1; Took action: up; Reward received: -1\n",
      "GAME: 6. Move #: 2; Took action: up; Reward received: -1\n",
      "GAME: 6. Move #: 3; Took action: up; Reward received: 100\n",
      "GAME: 7. Move #: 1; Took action: left; Reward received: 100\n",
      "GAME: 8. Move #: 1; Took action: left; Reward received: -1\n",
      "GAME: 8. Move #: 2; Took action: left; Reward received: -1\n",
      "GAME: 8. Move #: 3; Took action: left; Reward received: -1\n",
      "GAME: 8. Move #: 4; Took action: up; Reward received: -1\n",
      "GAME: 8. Move #: 5; Took action: up; Reward received: -1\n",
      "GAME: 8. Move #: 6; Took action: up; Reward received: 100\n",
      "GAME: 9. Move #: 1; Took action: up; Reward received: 100\n",
      "GAME: 10. Move #: 1; Took action: left; Reward received: -1\n",
      "GAME: 10. Move #: 2; Took action: left; Reward received: -1\n",
      "GAME: 10. Move #: 3; Took action: up; Reward received: 100\n",
      "Total games played=10. Of which 10 are won, 0 are lost, and 0 were abandoned\n"
     ]
    }
   ],
   "source": [
    "# Test on player mode\n",
    "agent.test(numGames=10, mode='player', display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total games played=25. Of which 20 are won, 1 are lost, and 4 were abandoned\n"
     ]
    }
   ],
   "source": [
    "# Test on random mode\n",
    "agent.test(numGames=25, mode='random', display=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94637411f088279a58f0325a9d3d1977a03a4c80559a2e9a4fe1ced1117d56be"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
