{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b30735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea351a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92002e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = env.reset().shape[0]\n",
    "h1_in = 60\n",
    "h1_out = 60\n",
    "n_actions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c664e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(state_dim, h1_in),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(h1_in, h1_out),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(h1_out, n_actions)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "15c9bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_size = 100\n",
    "batch_size = 20\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8c5e9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_batch = torch.empty((batch_size, state_dim))\n",
    "next_state_batch = torch.empty((batch_size, state_dim))\n",
    "\n",
    "action_batch = torch.empty((batch_size, 1))\n",
    "reward_batch = torch.empty((batch_size, 1))\n",
    "done_batch = torch.empty((batch_size, 1))\n",
    "\n",
    "for e in range(1000):\n",
    "    state = torch.from_numpy(env.reset())\n",
    "    q_vals = model(state)\n",
    "    action = torch.argmax(q_vals).item()\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    if e < batch_size:\n",
    "        state_batch[e] = state\n",
    "        next_state_batch[e] = torch.from_numpy(next_state)\n",
    "\n",
    "        action_batch[e] = action\n",
    "        reward_batch[e] = reward\n",
    "        done_batch[e] = done\n",
    "        \n",
    "        continue\n",
    "    \n",
    "        \n",
    "    elif e >= mem_size:\n",
    "        idx = e - (mem_size * (e // mem_size))\n",
    "        \n",
    "        state_batch[idx] = state\n",
    "        next_state_batch[idx] = torch.from_numpy(next_state)\n",
    "\n",
    "        action_batch[idx] = action\n",
    "        reward_batch[idx] = reward\n",
    "        done_batch[idx] = done\n",
    "\n",
    "    else:\n",
    "        state_batch = torch.cat((state_batch, torch.unsqueeze(state, dim=0)), dim=0)\n",
    "        \n",
    "        next_state = torch.from_numpy(next_state)\n",
    "        next_state_batch = torch.cat((next_state_batch, torch.unsqueeze(next_state, dim=0)), dim=0)\n",
    "\n",
    "        action_batch = torch.cat((action_batch, torch.unsqueeze(torch.tensor([action]), dim=0)), dim = 0)\n",
    "        reward_batch = torch.cat((reward_batch, torch.unsqueeze(torch.Tensor([reward]), dim=0)), dim = 0)\n",
    "        done_batch = torch.cat((done_batch, torch.unsqueeze(torch.Tensor([done]), dim=0)), dim = 0)\n",
    "        \n",
    "    random_indices = torch.randperm(action_batch.size(0))[:batch_size]\n",
    "    \n",
    "    q_vals = model(state_batch[random_indices])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        next_q_vals = model(next_state_batch[random_indices])\n",
    "    \n",
    "    y_hat = reward_batch[random_indices].squeeze() + 0.99*((1 - done_batch[random_indices]).squeeze() * torch.max(next_q_vals, dim=1)[0])\n",
    "    y = q_vals.gather(dim=1, index=action_batch[random_indices].long()).squeeze()\n",
    "    \n",
    "    loss = loss_func(y, y_hat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e00c7f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "99eec80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5ce46845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1324, -0.1366, -0.1319, -0.1319, -0.1325, -0.1381, -0.1349, -0.1383,\n",
       "        -0.1351, -0.1315, -0.1316, -0.1354, -0.1343, -0.1341, -0.1326, -0.1342,\n",
       "        -0.1343, -0.1351, -0.1350, -0.1347])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(next_q_vals, dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0a967666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done_batch[random_indices].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "67a859f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_batch[random_indices].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f27ecb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = torch.randperm(action_batch.size(0))[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4dfa04a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0416,  0.0145, -0.0046,  0.0005],\n",
       "        [-0.0493, -0.0073,  0.0488, -0.0389],\n",
       "        [-0.0007, -0.0101,  0.0003, -0.0284],\n",
       "        [-0.0149,  0.0474, -0.0225, -0.0311],\n",
       "        [ 0.0190, -0.0205, -0.0273,  0.0281],\n",
       "        [-0.0216, -0.0040, -0.0256,  0.0100],\n",
       "        [-0.0104,  0.0104, -0.0132, -0.0446],\n",
       "        [-0.0409,  0.0477,  0.0138, -0.0273],\n",
       "        [ 0.0102, -0.0423,  0.0332,  0.0462],\n",
       "        [-0.0231,  0.0452, -0.0144,  0.0348],\n",
       "        [-0.0311,  0.0152,  0.0057, -0.0378],\n",
       "        [-0.0427,  0.0253,  0.0421,  0.0162],\n",
       "        [-0.0194,  0.0420, -0.0220, -0.0297],\n",
       "        [-0.0480,  0.0176,  0.0118,  0.0230],\n",
       "        [-0.0425,  0.0382,  0.0073,  0.0297],\n",
       "        [ 0.0384, -0.0376,  0.0464, -0.0426],\n",
       "        [-0.0360, -0.0114, -0.0359,  0.0060],\n",
       "        [ 0.0396,  0.0203, -0.0165, -0.0270],\n",
       "        [ 0.0281, -0.0245, -0.0180, -0.0235],\n",
       "        [ 0.0045,  0.0113,  0.0145, -0.0107]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_batch[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0871a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. make empty tensor with shape = (batch_size, x)\n",
    "# 2. fill tensor by indexing until full. Is full when is filled with batch_size number of rows.\n",
    "# 3. stack tensor untill shape is (mem_size, x)\n",
    "# 4. add new rows to tensor by indexing. Every time index == mem_size -> index = 0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
